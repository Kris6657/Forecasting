{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e256e8d3-98d1-4c0c-bbde-d223e0c54977",
   "metadata": {},
   "source": [
    "# Data OverView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c365b-0c4c-4d97-b209-31f1773db99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20ff3e-d1d8-4020-9b42-0ce94db20c83",
   "metadata": {},
   "source": [
    "## I. Define a Funcwtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ebff9-6998-4dc3-bb0b-63cc0c716b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataset(from_drive = False):\n",
    "  if not os.path.exists(\"kaggle.json\"):\n",
    "    if not from_drive:\n",
    "      print(\"Upload Kaggle API Key\")\n",
    "      files.upload()\n",
    "      print(\"Downloading dataset...\")\n",
    "    else:\n",
    "      !cp /content/drive/MyDrive/kaggle.json /content/\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !cp kaggle.json ~/.kaggle/\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "    !kaggle datasets download -d saurabhshahane/electricity-load-forecasting\n",
    "    !unzip electricity-load-forecasting.zip\n",
    "  else:\n",
    "    print(\"Dataset already exists\")\n",
    "\n",
    "#We start with basic statistics for both numeric and categorical data\n",
    "def unistats(dataframe,sorted=\"Missing\"):\n",
    "    \"\"\"\"\n",
    "    Takes dataframe and sorted as parameter\n",
    "    Returns count, missing, unique, dtype, mode and other stats\"\"\"\n",
    "    pd.set_option(\"display.max_rows\",100)\n",
    "    pd.set_option(\"display.max_columns\",100)\n",
    "    output_df = pd.DataFrame(columns = [\"Count\",\"Missing\",\"Unique\", \"Dtype\", \"Mode\", \"Mean\", \"Min\", \"25%\", \"Median\", \"75%\", \"Max\", \"Std\", \"Skew\", \"Kurt\"])\n",
    "\n",
    "    for col in dataframe:\n",
    "        if pd.api.types.is_numeric_dtype(dataframe[col]):\n",
    "            output_df.loc[col] =[dataframe[col].count() ,dataframe[col].isnull().sum() ,dataframe[col].nunique() ,dataframe[col].dtype ,dataframe[col].mode().values[0], dataframe[col].mean(), dataframe[col].min(), dataframe[col].quantile(0.25), dataframe[col].median(), dataframe[col].quantile(0.75),dataframe[col].max(), dataframe[col].std(), dataframe[col].skew(),dataframe[col].kurt()]\n",
    "        else:\n",
    "            output_df.loc[col] =[dataframe[col].count() ,dataframe[col].isnull().sum() ,dataframe[col].nunique() ,dataframe[col].dtype , \"-\", \"-\", \"-\",\"-\", \"-\", \"-\",\"-\", \"-\", \"-\",\"-\"]\n",
    "\n",
    "\n",
    "    return output_df.sort_values(by = [\"Dtype\",sorted])\n",
    "\n",
    "def scatter(dataframe, target, feature):\n",
    "    from statsmodels.formula.api import ols\n",
    "    from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "    from scipy import stats\n",
    "    \"\"\"\n",
    "    Takes dataframe, target and feature as parameter\n",
    "    Use it with a numeric column\n",
    "    Fits an OLS model with the given feature\n",
    "    Applies breuschpagan test\n",
    "    Returns the scatterplot, regression and test results.\n",
    "    \"\"\"\n",
    "\n",
    "    sns.set_style(style=\"white\")\n",
    "\n",
    "    model = ols(formula= f\"{target}~{feature}\", data = dataframe).fit()\n",
    "\n",
    "    lm, p1, f, p2 = het_breuschpagan(model.resid,model.model.exog)\n",
    "    m, b, r, p, err = stats.linregress(dataframe[feature], dataframe[target])\n",
    "\n",
    "    string = \"y = \" + str(round(m,2)) + \"x \" + str(round(b,2)) + \"\\n\"\n",
    "    string += \"r_2 = \" + str(round(r**2, 4))  + \"\\n\"\n",
    "    string += str(round(r**2, 4)*100) + \"% of variance is explained\" + \"\\n\"\n",
    "    string += \"p = \" + str(round(p, 5)) + \"\\n\"\n",
    "    if p < 0.05:\n",
    "        string += \"Significant\" + \"\\n\"\n",
    "    else:\n",
    "        string += \"Not Significant\" + \"\\n\"\n",
    "    string += str(dataframe[feature].name) + \" skew = \" + str(round(dataframe[feature].skew(), 2)) + \"\\n\"\n",
    "    if dataframe[feature].skew() < 0:\n",
    "        string += str(dataframe[feature].name) + \" is negatively skewed\" + \"\\n\"\n",
    "    else:\n",
    "        string += str(dataframe[feature].name) + \" is positively skewed\" + \"\\n\"\n",
    "    string += str(dataframe[target].name) + \" skew = \" + str(round(dataframe[target].skew(), 2)) + \"\\n\"\n",
    "    if dataframe[target].skew() < 0:\n",
    "        string += str(dataframe[target].name) + \" is negatively skewed\" + \"\\n\"\n",
    "    else:\n",
    "        string += str(dataframe[target].name) + \" is positively skewed\" + \"\\n\"\n",
    "    string += str(dataframe[feature].name) + \" Breushpagan Test = \" + \"LM stat: \" + str(round(lm,4)) + \" p value: \" + str(round(p1,4)) + \" F stat: \" + str(round(f,4)) + \" p value: \" + str(round(p2,4)) + \"\\n\"\n",
    "    if p1 < 0.05:\n",
    "        string += \"Variance of residuals are not distributed equally\" + \"\\n\"\n",
    "    else:\n",
    "        string += \"Variance of residuals are distributed equally\" + \"\\n\"\n",
    "    ax = sns.jointplot(x = feature, y = target, kind = \"reg\", data = dataframe)\n",
    "    ax.fig.text( 1, 0.1, string, fontsize = 12, transform = plt.gcf().transFigure)\n",
    "\n",
    "def plot_predictions(test,predicted):\n",
    "    plt.plot(test, color='red',label='Real Demand')\n",
    "    plt.plot(predicted, color='green',label='Predicted Demand')\n",
    "    plt.title('Demand Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {}.\".format(rmse))\n",
    "\n",
    "def hist_and_boxplot(dataframe, label):\n",
    "    \"\"\"\n",
    "    Takes dataframe and feature as parameter\n",
    "    Returns histogram and boxplot\"\"\"\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.histplot(data = dataframe, x = label)\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.boxplot(data = dataframe, x = label)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961de26-1841-455b-b5f2-1ca69f5e2779",
   "metadata": {},
   "source": [
    "## II. Reading in Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cd502-6286-41f8-9119-49ea22287961",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"continuous dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820b1a-3b00-495f-afa1-069653378be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unistats(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6599b7-b3a0-4b10-924c-26d4ffe46a3f",
   "metadata": {},
   "source": [
    "### Overall Summary:\n",
    "1. Holiday and school variables show binary distributions indicating the presence or absence of holidays and school days.\n",
    "2. nat_demand shows significant variability and a near-normal distribution.\n",
    "3. Weather-related variables (temperature, humidity, precipitation, wind speed) exhibit various degrees of skewness and kurtosis, indicating different levels of variability and distribution shapes.\n",
    "4. datetime is a unique identifier for each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f2bdf-dc11-4a4c-a9dd-0b792a7f67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df[\"month\"] = df[\"datetime\"].dt.month\n",
    "df[\"day\"] = df[\"datetime\"].dt.day\n",
    "df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "df[\"dayofweek\"] = df[\"datetime\"].dt.dayofweek\n",
    "df[\"dayofyear\"] = df[\"datetime\"].dt.dayofyear\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4675a67-26af-4834-82ce-fd569df3246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"].min(), df[\"datetime\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec02c33-9c6b-450e-9c77-bfa67a41f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include = \"number\").columns:\n",
    "  hist_and_boxplot(df,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e432d-05bd-454a-882a-204ebf74836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_and_boxplot(df,\"nat_demand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156693d5-678b-4b2a-b2ec-05ca97067a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Value', dpi=100):\n",
    "    plt.figure(figsize=(16,5), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plot_df(df, x=df[\"datetime\"], y=df['nat_demand'], title='Time Series')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee995ca1-1692-4dec-acd1-f94a8d5304af",
   "metadata": {},
   "source": [
    "Due to the outbreak of the novel coronavirus at the end of 2019, which severely affected electricity consumption, only the data before the end of 2019 is being focused on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a31336-4676-4327-b887-0f7da27729a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"datetime\"] < \"2019-12-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd89b7-f4e7-47b1-b3a0-f487df88bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df, x=df[\"datetime\"], y=df['nat_demand'], title='Time Series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca247ccf-285a-4407-8346-08e79b777309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decomp_add = seasonal_decompose(df[\"nat_demand\"], period = 24*30)\n",
    "decomp_add.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3a91d-2a49-4c5b-9446-e0365ded954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_mul = seasonal_decompose(df[\"nat_demand\"], period = 24*30, model = \"multiplicative\")\n",
    "decomp_mul.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc9b9c-8dfb-436d-9763-3aa2ab0c7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "print('Results of Dickey-Fuller Test:')\n",
    "dftest = adfuller(df[\"nat_demand\"])\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cadac-e8d2-4cc0-b479-abc761f9ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A:自变量分布分析\n",
    "\n",
    "# A1.数值型变量分布\n",
    "num_cols = ['T2M_toc','QV2M_toc','TQL_toc','W2M_toc',\n",
    "            'T2M_san','QV2M_san','TQL_san','W2M_san',\n",
    "            'T2M_dav','QV2M_dav','TQL_dav','W2M_dav']\n",
    "\n",
    "plt.figure(figsize=(15,20))\n",
    "for i,col in enumerate(num_cols):\n",
    "    plt.subplot(6,4,i+1)\n",
    "    sns.kdeplot(data=df[col], fill=True) # Changed shade to fill\n",
    "    plt.title(f'{col} Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# A2.Boxplot展示数值变量分布\n",
    "plt.figure(figsize=(15,10))\n",
    "for i,col in enumerate(num_cols):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'{col} Boxplot')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# A3.离散型变量分布\n",
    "cat_cols = ['month','day', 'hour']\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, col in enumerate(cat_cols):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    if col in ['month', 'hour']:\n",
    "        sns.countplot(data=df, x=col, hue=col, palette='viridis', legend=False)\n",
    "    else:\n",
    "        df[col].value_counts().sort_index().plot(kind='bar', color='teal')\n",
    "    plt.title(f'{col} Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Part B:相关性分析\n",
    "# B1.Pearson相关系数矩阵\n",
    "corr_matrix = df[num_cols + ['nat_demand']].corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "heatmap = sns.heatmap(corr_matrix[['nat_demand']].sort_values('nat_demand',ascending=False),\n",
    "                      annot=True,fmt=\".2f\",vmin=-1,vmax=1,\n",
    "                      cmap='coolwarm',linewidths=.5)\n",
    "heatmap.set_title('Correlation with nat_demand',pad=12)\n",
    "plt.show()\n",
    "\n",
    "# B2.hour/day/month与需求 的关系\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.lineplot(data=df,x='hour',y='nat_demand',\n",
    "                 err_style=\"band\", # Modern error display style \n",
    "                 color='darkorange',\n",
    "                 linewidth=3,\n",
    "                 marker='o')\n",
    "ax.set_title('Hourly Demand Pattern with Confidence Interval',pad=10)\n",
    "ax.set_xlabel('Hour of Day',labelpad=10)\n",
    "ax.set_ylabel('Energy Demand',labelpad=10)\n",
    "plt.grid(True,alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.lineplot(data=df,x='day',y='nat_demand',\n",
    "                 err_style=\"band\", # Modern error display style \n",
    "                 color='darkorange',\n",
    "                 linewidth=3,\n",
    "                 marker='o')\n",
    "ax.set_title('Dayly Demand Pattern with Confidence Interval',pad=10)\n",
    "ax.set_xlabel('Day of Month',labelpad=10)\n",
    "ax.set_ylabel('Energy Demand',labelpad=10)\n",
    "plt.grid(True,alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.lineplot(data=df,x='month',y='nat_demand',\n",
    "                 err_style=\"band\", # Modern error display style \n",
    "                 color='darkorange',\n",
    "                 linewidth=3,\n",
    "                 marker='o')\n",
    "ax.set_title('Monthly Demand Pattern with Confidence Interval',pad=10)\n",
    "ax.set_xlabel('Month',labelpad=10)\n",
    "ax.set_ylabel('Energy Demand',labelpad=10)\n",
    "plt.grid(True,alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# B3.holiday影响分析\n",
    "import scipy.stats as stats\n",
    "\n",
    "holiday_data = [df[df['holiday']==0]['nat_demand'],\n",
    "                df[df['holiday']==1]['nat_demand']]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "box = sns.boxplot(x='holiday', y='nat_demand', data=df, \n",
    "                 hue='holiday', palette=['skyblue','salmon'], legend=False)\n",
    "\n",
    "test_result = stats.ttest_ind(*hol#iday_data)\n",
    "box.set_title(f'Holiday Impact (p-value={test_result.pvalue:.4f})')\n",
    "\n",
    "box.set_xticks([0, 1])\n",
    "box.set_xticklabels(['Normal Day', 'Holiday'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# B4.monthly趋势 (添加平滑处理)\n",
    "import statsmodels.api as sm\n",
    "plt.figure(figsize=(12,6))\n",
    "monthly_avg = df.groupby('month')['nat_demand'].mean().reset_index()\n",
    "sns.lineplot(x='month',y='nat_demand',data=monthly_avg,\n",
    "             estimator=None,lw=3,\n",
    "             marker='s',markersize=10,\n",
    "             label='Monthly Average')\n",
    "# Add smoothed trend line (optional)\n",
    "lowess_smoothed = sm.nonparametric.lowess(\n",
    "    monthly_avg['nat_demand'], monthly_avg['month'], frac=0.33)\n",
    "plt.plot(lowess_smoothed[:,0], lowess_smoothed[:,1],\n",
    "         'r--',lw=3,\n",
    "         label='Smoothed Trend')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b4f9a6-7e56-4737-9816-1e5886a53b16",
   "metadata": {},
   "source": [
    "# Pattern Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd7411-6e04-493d-8af3-72ac2718591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489247a9-1c9b-4128-b4c6-0ac72b3987a4",
   "metadata": {},
   "source": [
    "## I. start with basic statistics for both numeric and categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32348490-f190-4d3e-983c-f7a12bf587ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unistats(dataframe,sorted=\"Missing\"):\n",
    "    \"\"\"\"\n",
    "    Takes dataframe and sorted as parameter\n",
    "    Returns count, missing, unique, dtype, mode and other stats\n",
    "    \"\"\"\n",
    "    pd.set_option(\"display.max_rows\",100)\n",
    "    pd.set_option(\"display.max_columns\",100)\n",
    "    output_df = pd.DataFrame(columns = [\"Count\",\"Missing\",\"Unique\", \"Dtype\", \"Mode\", \"Mean\", \"Min\", \"25%\", \"Median\", \"75%\", \"Max\", \"Std\", \"Skew\", \"Kurt\"])\n",
    "\n",
    "    for col in dataframe:\n",
    "        if pd.api.types.is_numeric_dtype(dataframe[col]):\n",
    "            output_df.loc[col] =[dataframe[col].count() ,dataframe[col].isnull().sum() ,dataframe[col].nunique() ,dataframe[col].dtype ,dataframe[col].mode().values[0], dataframe[col].mean(), dataframe[col].min(), dataframe[col].quantile(0.25), dataframe[col].median(), dataframe[col].quantile(0.75),dataframe[col].max(), dataframe[col].std(), dataframe[col].skew(),dataframe[col].kurt()]\n",
    "        else:\n",
    "            output_df.loc[col] =[dataframe[col].count() ,dataframe[col].isnull().sum() ,dataframe[col].nunique() ,dataframe[col].dtype , \"-\", \"-\", \"-\",\"-\", \"-\", \"-\",\"-\", \"-\", \"-\",\"-\"]\n",
    "\n",
    "\n",
    "    return output_df.sort_values(by = [\"Dtype\",sorted])\n",
    "\n",
    "def scatter(dataframe, target, feature):\n",
    "    from statsmodels.formula.api import ols\n",
    "    from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "    from scipy import stats\n",
    "    \"\"\"\n",
    "    Takes dataframe, target and feature as parameter\n",
    "    Use it with a numeric column\n",
    "    Fits an OLS model with the given feature\n",
    "    Applies breuschpagan test\n",
    "    Returns the scatterplot, regression and test results.\n",
    "    \"\"\"\n",
    "\n",
    "    sns.set_style(style=\"white\")\n",
    "\n",
    "    model = ols(formula= f\"{target}~{feature}\", data = dataframe).fit()\n",
    "\n",
    "    lm, p1, f, p2 = het_breuschpagan(model.resid,model.model.exog)\n",
    "    m, b, r, p, err = stats.linregress(dataframe[feature], dataframe[target])\n",
    "\n",
    "    string = \"y = \" + str(round(m,2)) + \"x \" + str(round(b,2)) + \"\\n\"\n",
    "    string += \"r_2 = \" + str(round(r**2, 4))  + \"\\n\"\n",
    "    string += str(round(r**2, 4)*100) + \"% of variance is explained\" + \"\\n\"\n",
    "    string += \"p = \" + str(round(p, 5)) + \"\\n\"\n",
    "    if p < 0.05:\n",
    "        string += \"Significant\" + \"\\n\"\n",
    "    else:\n",
    "        string += \"Not Significant\" + \"\\n\"\n",
    "    string += str(dataframe[feature].name) + \" skew = \" + str(round(dataframe[feature].skew(), 2)) + \"\\n\"\n",
    "    if dataframe[feature].skew() < 0:\n",
    "        string += str(dataframe[feature].name) + \" is negatively skewed\" + \"\\n\"\n",
    "    else:\n",
    "        string += str(dataframe[feature].name) + \" is positively skewed\" + \"\\n\"\n",
    "    string += str(dataframe[target].name) + \" skew = \" + str(round(dataframe[target].skew(), 2)) + \"\\n\"\n",
    "    if dataframe[target].skew() < 0:\n",
    "        string += str(dataframe[target].name) + \" is negatively skewed\" + \"\\n\"\n",
    "    else:\n",
    "        string += str(dataframe[target].name) + \" is positively skewed\" + \"\\n\"\n",
    "    string += str(dataframe[feature].name) + \" Breushpagan Test = \" + \"LM stat: \" + str(round(lm,4)) + \" p value: \" + str(round(p1,4)) + \" F stat: \" + str(round(f,4)) + \" p value: \" + str(round(p2,4)) + \"\\n\"\n",
    "    if p1 < 0.05:\n",
    "        string += \"Variance of residuals are not distributed equally\" + \"\\n\"\n",
    "    else:\n",
    "        string += \"Variance of residuals are distributed equally\" + \"\\n\"\n",
    "    ax = sns.jointplot(x = feature, y = target, kind = \"reg\", data = dataframe)\n",
    "    ax.fig.text( 1, 0.1, string, fontsize = 12, transform = plt.gcf().transFigure)\n",
    "\n",
    "def plot_predictions(test,predicted):\n",
    "    plt.plot(test, color='red',label='Real Demand')\n",
    "    plt.plot(predicted, color='green',label='Predicted Demand')\n",
    "    plt.title('Demand Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {}.\".format(rmse))\n",
    "\n",
    "def hist_and_boxplot(dataframe, label):\n",
    "    \"\"\"\n",
    "    Takes dataframe and feature as parameter\n",
    "    Returns histogram and boxplot\"\"\"\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.histplot(data = dataframe, x = label)\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.boxplot(data = dataframe, x = label)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900b3dc-c1f6-4267-b6f6-ccfebc2ba388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"continuous dataset_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603bd93-6425-461b-9694-cefd05ac4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe34fa4-fa92-4fcf-88cb-d55e6c8551fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unistats(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ada172-9b07-4a26-b602-734d09435bdf",
   "metadata": {},
   "source": [
    "* lets create some datetime features,\n",
    "* Since electricity demand is highly correlated with day and hour. \n",
    "* These features will help us to interpret and gain insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17645cfb-9ef7-462f-ba71-46cb87e61aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df[\"month\"] = df[\"datetime\"].dt.month\n",
    "df[\"day\"] = df[\"datetime\"].dt.day\n",
    "df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "df[\"dayofweek\"] = df[\"datetime\"].dt.dayofweek\n",
    "df[\"dayofyear\"] = df[\"datetime\"].dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c8fce-17e2-42ca-a652-ab496530d571",
   "metadata": {},
   "source": [
    "## II. lets look at the date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de418a3-56a0-4639-9e78-5c82ec585278",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"].min(), df[\"datetime\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb52f2-b195-429f-8737-bf9f7192dc3c",
   "metadata": {},
   "source": [
    "## III. lets look at the histograms of numeric columns to better understand the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4266d-27ed-48a7-a157-0dd378b92571",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include = \"number\").columns:\n",
    "  hist_and_boxplot(df,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db3502-f10e-4bf2-b368-26e1242cff85",
   "metadata": {},
   "source": [
    "## IV. Lets dive into nat demand column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c7625-0d82-4268-ba76-8c86c3fc06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_and_boxplot(df,\"nat_demand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0b672-f6df-4d39-b8a0-0644b9818cb8",
   "metadata": {},
   "source": [
    "### Observe some outliers and want to look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdbbc3-b432-4744-8ec1-9f7ee3b88808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"nat_demand\"] <500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4cb9d-7087-40e7-8b54-ff95d5979990",
   "metadata": {},
   "source": [
    "## V. Lets visualize the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af2091-0745-4872-984b-fb5f5d8e20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Value', dpi=100):\n",
    "    plt.figure(figsize=(16,5), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plot_df(df, x=df[\"datetime\"], y=df['nat_demand'], title='Time Series')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ba621-140f-465f-b8bf-7f30aca09224",
   "metadata": {},
   "source": [
    "* Here we can see that the data is from 2015 to 2020 which is the year of pandemic.\n",
    "* Since the pandemic highly affected the electricity usage I will only look at till the start of pandemic which is late 2019.\n",
    "* For consistency I will change these values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd1d7f-6153-43c2-bbb7-1736f8592a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"datetime\"] < \"2019-12-31\"]\n",
    "df.loc[df[\"nat_demand\"] <500,\"nat_demand\"] = df[\"nat_demand\"].mean()\n",
    "plot_df(df, x=df[\"datetime\"], y=df['nat_demand'], title='Time Series')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675f901-523d-47cc-8be7-fe5fa982fd3d",
   "metadata": {},
   "source": [
    "* Since it is hourly, hard to catch trends and seasoanility. Hence lets decompose it and try to see these effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1191d-8f9d-453b-8711-dae12dee24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decomp_add = seasonal_decompose(df[\"nat_demand\"], period = 24*365)\n",
    "decomp_add.plot();\n",
    "decomp_mul = seasonal_decompose(df[\"nat_demand\"], period = 24*365, model = \"multiplicative\")\n",
    "decomp_mul.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c90e2-f868-470a-8604-2298db90a602",
   "metadata": {},
   "source": [
    "## VI. Draw the seasonal proportions for the first three years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9dc8f5-b55f-4e21-9801-758d98915779",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "seasonal = decomp_add.seasonal\n",
    "\n",
    "#seasonal = decomp_mul.seasonal\n",
    "\n",
    "# first year （0 to 8760）\n",
    "time_index_1 = pd.date_range(start='2015-01-03 01:00', periods=8760, freq='h')\n",
    "plt.plot(time_index_1, seasonal[:8760], label=\"Year 1 (2015)\", alpha=0.7)\n",
    "\n",
    "# Second year（8760 to 17520）\n",
    "time_index_2 = pd.date_range(start='2016-01-03 01:00', periods=8760, freq='h')\n",
    "plt.plot(time_index_2, seasonal[8760:17520], label=\"Year 2 (2016)\", alpha=0.7)\n",
    "\n",
    "# Third year（17520 to 26280）\n",
    "time_index_3 = pd.date_range(start='2017-01-03 01:00', periods=8760, freq='h')\n",
    "plt.plot(time_index_3, seasonal[17520:26280], label=\"Year 3 (2017)\", alpha=0.7)\n",
    "\n",
    "plt.title(\"Seasonal Component (First 3 Years)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Seasonal (MW)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf6d29-47f9-4081-b625-7207001be55a",
   "metadata": {},
   "source": [
    "* In the seasonal chart, fluctuations repeat in cycles of 8,760 hours (approximately 4.57 cycles within 40,000 hours).\n",
    "* Within each 8,760 hour segment, the distribution of peaks and troughs is similar (for example, peaks may correspond to winter and summer, and troughs to spring and autumn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5bc89-c2aa-4c0d-baf3-15ced8445d58",
   "metadata": {},
   "source": [
    "## VII. check the stationality,We reject the null hypothesis that the nat demand is stationary since p value is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd190670-6863-458c-98dc-74cb23109068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "print('Results of Dickey-Fuller Test:')\n",
    "dftest = adfuller(df[\"nat_demand\"])\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56943220-f0c2-4701-8efa-26df7b1fe632",
   "metadata": {},
   "source": [
    "## VIII. check the stationality,We reject the null hypothesis that the nat demand is stationary since p value is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd7cf3-ba58-4642-8d67-e748e02697d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "print('Results of Dickey-Fuller Test:')\n",
    "dftest = adfuller(df[\"nat_demand\"])\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2affd-d47a-4687-8c23-d34a2070dd35",
   "metadata": {},
   "source": [
    "## IX. Lets also look by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da760960-3863-42e9-9ad8-afb2190ba736",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_con_winter = df[df[\"month\"].isin([12,1,2])]\n",
    "energy_con_summer = df[df[\"month\"].isin([6,7,8])]\n",
    "sns.boxplot(data = energy_con_winter, x = \"hour\", y = \"nat_demand\")\n",
    "sns.boxplot(data = energy_con_summer, x = \"hour\", y = \"nat_demand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab158590-3ec8-4c74-828b-26aeef82eb3c",
   "metadata": {},
   "source": [
    "* High electricity consumption might be due to the hot weather during the dry season, which increases the demand for air conditioners. Furthermore, the dry season is the peak tourist season and economic activities increase.\n",
    "* In June, July and August (the rainy season), the electricity consumption is low. This might be due to the frequent rainfall during the rainy season and the slightly lower (but still higher) temperature, which leads to a decrease in the demand for air conditioners. The rainy season may reduce outdoor activities and lower electricity consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391c606-07e9-4421-a2a6-a0336a7742b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## X. Create a season column to retain only December, January, February and June, July, August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d593e-e060-4544-91f9-7ed08a8466e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[df[\"month\"].isin([12, 1, 2, 6, 7, 8])]\n",
    "df_subset[\"season\"] = df_subset[\"month\"].map({\n",
    "    12: \"Dry Season (Dec-Feb)\", 1: \"Dry Season (Dec-Feb)\", 2: \"Dry Season (Dec-Feb)\",\n",
    "    6: \"Rainy Season (Jun-Aug)\", 7: \"Rainy Season (Jun-Aug)\", 8: \"Rainy Season (Jun-Aug)\"\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=\"hour\", y=\"nat_demand\", hue=\"season\", data=df_subset)\n",
    "plt.title(\"Electricity Demand by Hour: Dry Season (Dec-Feb) vs Rainy Season (Jun-Aug) in Panama\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"nat_demand (MW)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b9921-9a23-45d9-8748-4ae7a580e3c2",
   "metadata": {},
   "source": [
    "* Here the orange boxplots represent the usage in winter.\n",
    "* As we can see, the usage in winter is higher than summer.\n",
    "* Hence we conclude there is seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c79b0c-4f81-4871-81ed-270574645f3e",
   "metadata": {},
   "source": [
    "### Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98692c-d00f-4a90-89d4-c15b17e70d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = df, x = \"dayofweek\", y = \"nat_demand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d5c43-4c79-49b9-a555-084fa28b720e",
   "metadata": {},
   "source": [
    "* We can see that weekdays are higher in the usage of electricity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e87cb-e800-4481-98ec-3dff68cfafc4",
   "metadata": {},
   "source": [
    "### hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c088cb-b660-4143-978b-97da5fb65e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = df, x = \"hour\", y = \"nat_demand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1d536-2552-4f1e-afeb-efdf23afd57e",
   "metadata": {},
   "source": [
    "* Hourly effect can be seen easily, at night there is little and peek at 11-12 mid-day and again decrease till the night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de62d22-2989-4ef8-82a2-17665831a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[\"T2M_toc\"], df[\"nat_demand\"])\n",
    "plt.xlabel(\"Temperature (T2M_toc)\")\n",
    "plt.ylabel(\"Demand (MW)\")\n",
    "plt.title(\"Demand vs Temperature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2958a59-f2e3-47c0-9265-24fa4c4c71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=\"nat_demand\", by=\"holiday\")\n",
    "plt.title(\"Demand by Holiday\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ae4cd-61be-492d-93ae-bfdf79563b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_year = seasonal_decompose(df[\"nat_demand\"], period=24*365, model=\"multiplicative\")\n",
    "decomp_year.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544328b6-e7ab-4288-8913-3442f758be2e",
   "metadata": {},
   "source": [
    "## XI. ACF test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96faf4-b5f8-456c-ab7a-0c26e78aacce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acf = pd.read_csv(\"continuous dataset_en.csv\", parse_dates=['datetime'], index_col='datetime')['nat_demand']\n",
    "lags = 96\n",
    "acf_values, confint = acf(data_acf, nlags=lags, alpha=0.05)\n",
    "\n",
    "lower_conf = confint[:, 0] - acf_values\n",
    "upper_conf = confint[:, 1] - acf_values\n",
    "\n",
    "#draw figure\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.stem(range(lags + 1), acf_values, markerfmt='bo', basefmt='k-')\n",
    "plt.fill_between(range(lags + 1), lower_conf, upper_conf, color='red', alpha=0.5)\n",
    "plt.title('Autocorrelation Function (ACF) with Confidence Intervals')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d310530c-1859-4279-87f9-658fc75003fb",
   "metadata": {},
   "source": [
    "# Winters Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b304d8a-2643-4d0a-8392-86ca15c44c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e8438-8d33-439e-a6f1-817a4ec4ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载和预处理数据\n",
    "def load_and_preprocess_data(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"文件路径不存在：{filepath}\")\n",
    "\n",
    "    try:\n",
    "        # 读取 Excel 文件\n",
    "        data = pd.read_csv(filepath) #文件格式\n",
    "\n",
    "        # 检查日期列是否存在\n",
    "        if 'datetime' not in data.columns or 'nat_demand' not in data.columns:\n",
    "            raise KeyError(\"数据缺少必要的列：'日期（2015-2019）' 或 '国家电力负载'\")\n",
    "        \n",
    "        # 设置日期为索引，并选择电力负载列\n",
    "        data.set_index('datetime', inplace=True)\n",
    "        series = data['nat_demand']\n",
    "\n",
    "        # 填充缺失值（例如使用线性插值）\n",
    "        series = series.interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "        # 重采样为每日数据（求均值）\n",
    "        daily_series = series.resample('D').mean()\n",
    "\n",
    "        return daily_series\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"数据加载和预处理失败：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d5f1b-8038-4578-b286-f6c3d4fc161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holt-Winters 模型实现\n",
    "class HoltWinters:\n",
    "    def __init__(self, series, seasonal_periods=365, alpha=0.2, beta=0.1, gamma=0.3):\n",
    "        if len(series) < seasonal_periods:\n",
    "            raise ValueError(f\"时间序列长度不足，至少需要 {seasonal_periods} 个数据点。\")\n",
    "\n",
    "        self.series = series\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.seasonal_periods = seasonal_periods\n",
    "        self.level = None\n",
    "        self.trend = None\n",
    "        self.seasonal = None\n",
    "        self.forecast = None\n",
    "\n",
    "    def initialize(self):\n",
    "        self.level = np.mean(self.series[:self.seasonal_periods])\n",
    "        first_period = self.series[:self.seasonal_periods]\n",
    "        second_period = self.series[self.seasonal_periods:2*self.seasonal_periods]\n",
    "\n",
    "        self.trend = (np.mean(second_period) - np.mean(first_period)) / self.seasonal_periods \\\n",
    "            if len(second_period) > 0 else 0\n",
    "\n",
    "        self.seasonal = np.zeros(self.seasonal_periods)\n",
    "        for i in range(self.seasonal_periods):\n",
    "            self.seasonal[i] = self.series[i] / self.level if i < len(self.series) else 1.0\n",
    "\n",
    "    def fit(self):\n",
    "        self.initialize()\n",
    "        result = []\n",
    "        seasonals = self.seasonal.copy()\n",
    "\n",
    "        for i in range(len(self.series)):\n",
    "            old_level = self.level\n",
    "            old_trend = self.trend\n",
    "        return np.array(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab0840-f167-4c1f-bb77-02dbca716527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确性指标\n",
    "def calculate_metrics(actual, predicted):\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034a010-f786-46c3-bf08-202610bee99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网格搜索优化参数\n",
    "def grid_search_holt_winters(train, test, seasonal_periods=365):\n",
    "    # 定义参数范围\n",
    "    alpha_range = np.arange(0.1, 1.0, 0.2)  # [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    beta_range = np.arange(0.1, 0.5, 0.2)   # [0.1, 0.3]\n",
    "    gamma_range = np.arange(0.1, 0.5, 0.2)  # [0.1, 0.3]\n",
    "\n",
    "    best_mae = float('inf')\n",
    "    best_params = None\n",
    "    best_forecast = None\n",
    "\n",
    "    # 遍历所有参数组合\n",
    "    for alpha, beta, gamma in itertools.product(alpha_range, beta_range, gamma_range):\n",
    "        try:\n",
    "            # 训练模型\n",
    "            model = HoltWinters(train, seasonal_periods=seasonal_periods, alpha=alpha, beta=beta, gamma=gamma)\n",
    "            model.fit()\n",
    "\n",
    "            # 预测\n",
    "            forecast = model.predict(len(test))\n",
    "\n",
    "            # 计算 MAE\n",
    "            mae = mean_absolute_error(test, forecast)\n",
    "\n",
    "            # 更新最佳参数\n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_params = {'alpha': alpha, 'beta': beta, 'gamma': gamma}\n",
    "                best_forecast = forecast\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"参数组合 (alpha={alpha}, beta={beta}, gamma={gamma}) 失败: {e}\")\n",
    "            continue\n",
    "\n",
    "    return best_params, best_forecast, best_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69095d90-4738-4a7a-ad3c-7ab1dd43869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主函数\n",
    "def main():\n",
    "    # 使用您的文件路径\n",
    "    filepath = 'continuous dataset_en.csv'\n",
    "\n",
    "    try:\n",
    "        series = load_and_preprocess_data(filepath)\n",
    "\n",
    "        train = series[:-30]\n",
    "        test = series[-30:]\n",
    "\n",
    "        # 进行网格搜索\n",
    "        print(\"开始网格搜索以优化参数...\")\n",
    "        best_params, forecast, best_mae = grid_search_holt_winters(train, test, seasonal_periods=365)\n",
    "        print(f\"最佳参数: alpha={best_params['alpha']}, beta={best_params['beta']}, gamma={best_params['gamma']}\")\n",
    "        print(f\"最佳 MAE: {best_mae:.2f}\")\n",
    "\n",
    "        # 使用最佳参数重新训练模型\n",
    "        model = HoltWinters(train, seasonal_periods=365, \n",
    "                           alpha=best_params['alpha'], \n",
    "                           beta=best_params['beta'], \n",
    "                           gamma=best_params['gamma'])\n",
    "        model.fit()\n",
    "        \n",
    "\n",
    "        metrics = calculate_metrics(test, forecast)\n",
    "\n",
    "        print(\"Holt-Winters 预测结果：\")\n",
    "        print(\"\\n准确性指标：\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.2f}\")\n",
    "\n",
    "        results = pd.DataFrame({\n",
    "            'Actual': test,\n",
    "            'Predicted': forecast\n",
    "        }, index=test.index)\n",
    "\n",
    "        results.to_csv('holt_winters_forecast_results.csv')\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(results.index, results['Actual'], label='Actual')\n",
    "        plt.plot(results.index, results['Predicted'], label='Predicted')\n",
    "        plt.title('Winters Method Results(Test-Last 30 days)')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig('holt_winters_forecast.png')\n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"运行失败：{e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf9ac35-a846-4dc6-ad7f-e71cf8b3d761",
   "metadata": {},
   "source": [
    "# ARIMA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92df5a2-e365-423e-b93e-10f20d085dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "from statsmodels.tsa.arima.model import ARIMA  \n",
    "from statsmodels.tsa.stattools import adfuller  \n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf  \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')  \n",
    "import matplotlib.dates as mdates  \n",
    "from statsmodels.tsa.seasonal import seasonal_decompose  \n",
    "import statsmodels.api as sm  \n",
    "import os  \n",
    "from datetime import datetime, timedelta  \n",
    "  \n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']   \n",
    "plt.rcParams['axes.unicode_minus'] = False    \n",
    "\n",
    "# 1. data\n",
    "print(\"1. 数据加载与预处理\")  \n",
    "df = pd.read_csv(\"continuous dataset_en.csv\", parse_dates=['datetime'])  \n",
    "df.set_index('datetime', inplace=True) \n",
    "\n",
    "# 检查并处理缺失值  \n",
    "print(f\"原始数据形状: {df.shape}\")  \n",
    "print(f\"缺失值数量:\\n{df.isna().sum()}\")  \n",
    "\n",
    "# 填充缺失值 (如果有)  \n",
    "if df.isna().sum().sum() > 0:  \n",
    "    print(\"处理缺失值...\")  \n",
    "    # 对时间序列数据，通常使用前向填充  \n",
    "    df = df.fillna(method='ffill')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21baf6-ad30-40ff-994b-5b7447fdf102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 基本数据探索  \n",
    "print(\"\\n2. 数据探索\")  \n",
    "print(f\"数据范围: {df.index.min()} 至 {df.index.max()}\")  \n",
    "print(f\"数据描述性统计:\\n{df['nat_demand'].describe()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab96e52-bb88-4e34-816e-7d619f292bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 可视化原始数据  \n",
    "plt.figure(figsize=(15, 6))  \n",
    "plt.plot(df.index, df['nat_demand'])  \n",
    "plt.title('电力需求时间序列图 (nat_demand)')  \n",
    "plt.xlabel('日期')  \n",
    "plt.ylabel('需求量')  \n",
    "plt.grid(True)  \n",
    "plt.tight_layout()  \n",
    "plt.savefig('电力需求时间序列图.png', dpi=300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa3e744-40d0-409f-be9e-5f8e34b5e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 时间序列分解  \n",
    "print(\"\\n3. 时间序列分解\")  \n",
    "# 分解时间序列以观察趋势、季节性和残差  \n",
    "decomposition = seasonal_decompose(df['nat_demand'], model='additive', period=24)  # 每日24小时周期  \n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12))  \n",
    "decomposition.observed.plot(ax=axes[0])  \n",
    "axes[0].set_title('原始数据')  \n",
    "axes[0].set_ylabel('需求量')  \n",
    "decomposition.trend.plot(ax=axes[1])  \n",
    "axes[1].set_title('趋势')  \n",
    "axes[1].set_ylabel('趋势')  \n",
    "decomposition.seasonal.plot(ax=axes[2])  \n",
    "axes[2].set_title('季节性')  \n",
    "axes[2].set_ylabel('季节性')  \n",
    "decomposition.resid.plot(ax=axes[3])  \n",
    "axes[3].set_title('残差')  \n",
    "axes[3].set_ylabel('残差')  \n",
    "plt.tight_layout()  \n",
    "plt.savefig('时间序列分解.png', dpi=300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3a00b-5d43-43b7-8d1e-2f8f0719ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 平稳性检验  \n",
    "print(\"\\n4. 平稳性检验 (ADF测试)\")  \n",
    "def adf_test(series):  \n",
    "    result = adfuller(series.dropna())  \n",
    "    print(f'ADF统计量: {result[0]}')  \n",
    "    print(f'p值: {result[1]}')  \n",
    "    print(f'临界值:')  \n",
    "    for key, value in result[4].items():  \n",
    "        print(f'\\t{key}: {value}')  \n",
    "    if result[1] <= 0.05:  \n",
    "        print(\"=> 序列是平稳的 (拒绝原假设)\")  \n",
    "    else:  \n",
    "        print(\"=> 序列不平稳 (未拒绝原假设)\")  \n",
    "    return result[1] <= 0.05  \n",
    "\n",
    "# 对原始数据进行平稳性检验  \n",
    "is_stationary = adf_test(df['nat_demand'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c3e77-c9c5-4cbb-a1f3-96be6fce76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 如果数据不平稳，进行差分处理  \n",
    "if not is_stationary:  \n",
    "    print(\"\\n5. 进行差分处理\")  \n",
    "    # 一阶差分  \n",
    "    df['nat_demand_diff1'] = df['nat_demand'].diff()  \n",
    "    \n",
    "    # 再次检验平稳性  \n",
    "    plt.figure(figsize=(15, 6))  \n",
    "    plt.plot(df.index[1:], df['nat_demand_diff1'][1:])  \n",
    "    plt.title('电力需求一阶差分')  \n",
    "    plt.xlabel('日期')  \n",
    "    plt.ylabel('差分值')  \n",
    "    plt.grid(True)  \n",
    "    plt.tight_layout()  \n",
    "    plt.savefig('一阶差分.png', dpi=300)  \n",
    "    \n",
    "    print(\"\\n一阶差分后的平稳性检验:\")  \n",
    "    is_stationary_diff1 = adf_test(df['nat_demand_diff1'])  \n",
    "    \n",
    "    # 如果一阶差分后仍不平稳，尝试季节性差分  \n",
    "    if not is_stationary_diff1:  \n",
    "        print(\"\\n进行季节性差分 (24小时)...\")  \n",
    "        df['nat_demand_seasonal_diff'] = df['nat_demand'].diff(24)  \n",
    "        \n",
    "        plt.figure(figsize=(15, 6))  \n",
    "        plt.plot(df.index[24:], df['nat_demand_seasonal_diff'][24:])  \n",
    "        plt.title('电力需求季节性差分 (周期=24小时)')  \n",
    "        plt.xlabel('日期')  \n",
    "        plt.ylabel('季节性差分值')  \n",
    "        plt.grid(True)  \n",
    "        plt.tight_layout()  \n",
    "        plt.savefig('季节性差分.png', dpi=300)  \n",
    "        \n",
    "        print(\"\\n季节性差分后的平稳性检验:\")  \n",
    "        is_stationary_seasonal = adf_test(df['nat_demand_seasonal_diff'])  \n",
    "else:  \n",
    "    print(\"数据已经是平稳的，无需差分处理\")  \n",
    "    df['nat_demand_diff1'] = df['nat_demand']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec06ec-59b5-405a-9b05-f36bf5d87696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 确定ARIMA模型参数 - ACF和PACF图  \n",
    "print(\"\\n6. 确定ARIMA模型参数\")  \n",
    "# 使用差分后的数据  \n",
    "diff_data = df['nat_demand_diff1'].dropna()  \n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))  \n",
    "plot_acf(diff_data, lags=48, ax=axes[0])  # 48小时的滞后  \n",
    "axes[0].set_title('自相关函数 (ACF)')  \n",
    "plot_pacf(diff_data, lags=48, ax=axes[1])  \n",
    "axes[1].set_title('偏自相关函数 (PACF)')  \n",
    "plt.tight_layout()  \n",
    "plt.savefig('ACF_PACF图.png', dpi=300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a0877-12bd-4416-b660-0471de4370a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 拆分训练集和测试集  \n",
    "print(\"\\n7. 拆分训练集和测试集\")  \n",
    "# 使用80%数据作为训练集，20%作为测试集  \n",
    "train_size = int(len(df) * 0.8)  \n",
    "train_data = df.iloc[:train_size]  \n",
    "test_data = df.iloc[train_size:]  \n",
    "\n",
    "print(f\"训练集大小: {len(train_data)}\")  \n",
    "print(f\"测试集大小: {len(test_data)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1fe7a-4b40-4182-b611-e94b75105e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 拟合ARIMA模型  \n",
    "print(\"\\n8. 拟合ARIMA模型\")  \n",
    "\n",
    "p, d, q = 2, 1, 2 \n",
    "\n",
    "# 创建和训练ARIMA模型  \n",
    "model = ARIMA(train_data['nat_demand'], order=(p, d, q))  \n",
    "model_fit = model.fit()  \n",
    "print(model_fit.summary())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878db15d-7c9c-48ab-8997-b1cb2c89395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 模型诊断  \n",
    "print(\"\\n9. 模型诊断\")  \n",
    "# 残差分析  \n",
    "residuals = model_fit.resid  \n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))  \n",
    "\n",
    "# 残差时间序列图  \n",
    "axes[0, 0].plot(residuals)  \n",
    "axes[0, 0].set_title('残差时间序列')  \n",
    "axes[0, 0].set_xlabel('时间')  \n",
    "axes[0, 0].set_ylabel('残差')  \n",
    "\n",
    "# 残差直方图  \n",
    "axes[0, 1].hist(residuals, bins=30)  \n",
    "axes[0, 1].set_title('残差直方图')  \n",
    "axes[0, 1].set_xlabel('残差')  \n",
    "axes[0, 1].set_ylabel('频率')  \n",
    "\n",
    "# 残差ACF图  \n",
    "plot_acf(residuals, lags=40, ax=axes[1, 0])  \n",
    "axes[1, 0].set_title('残差自相关函数')  \n",
    "\n",
    "# 残差Q-Q图  \n",
    "import scipy.stats as stats  \n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 1])  \n",
    "axes[1, 1].set_title('残差Q-Q图')  \n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.savefig('模型诊断.png', dpi=300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878a80d-5a67-4df3-82f2-6ae808e0f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. 进行预测  \n",
    "print(\"\\n10. 进行预测\")  \n",
    "# 在测试集上进行预测  \n",
    "predictions = model_fit.forecast(steps=len(test_data))  \n",
    "\n",
    "# 创建包含预测值的DataFrame  \n",
    "pred_df = pd.DataFrame({  \n",
    "    'Actual': test_data['nat_demand'],  \n",
    "    'Predicted': predictions  \n",
    "})  \n",
    "\n",
    "# 可视化预测结果  \n",
    "plt.figure(figsize=(15, 6))  \n",
    "plt.plot(test_data.index, test_data['nat_demand'], label='实际值')  \n",
    "plt.plot(test_data.index, predictions, color='red', label='预测值')  \n",
    "plt.title('ARIMA模型预测结果')  \n",
    "plt.xlabel('日期')  \n",
    "plt.ylabel('电力需求')  \n",
    "plt.legend()  \n",
    "plt.grid(True)  \n",
    "plt.tight_layout()  \n",
    "plt.savefig('预测结果.png', dpi=300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200be10-173e-4f0e-acba-aaf753797bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. 评估模型性能  \n",
    "print(\"\\n11. 评估模型性能\")  \n",
    "# 计算均方误差、均方根误差和平均绝对误差  \n",
    "mse = mean_squared_error(test_data['nat_demand'], predictions)  \n",
    "rmse = np.sqrt(mse)  \n",
    "mae = mean_absolute_error(test_data['nat_demand'], predictions)  \n",
    "\n",
    "print(f\"均方误差 (MSE): {mse:.4f}\")  \n",
    "print(f\"均方根误差 (RMSE): {rmse:.4f}\")  \n",
    "print(f\"平均绝对误差 (MAE): {mae:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e400db-9812-4124-9cfc-b2e62e8e1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. 分析外部变量的影响 (可选)  \n",
    "print(\"\\n12. 分析自变量的影响\")  \n",
    "# 检查自变量与电力需求的相关性  \n",
    "plt.figure(figsize=(12, 10))  \n",
    "correlation_matrix = df[['nat_demand', 'T2M_toc', 'QV2M_toc', 'TQL_toc', 'W2M_toc',   \n",
    "                       'T2M_san', 'QV2M_san', 'TQL_san', 'W2M_san',  \n",
    "                       'T2M_dav', 'QV2M_dav', 'TQL_dav', 'W2M_dav']].corr()  \n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')  \n",
    "plt.title('自变量与电力需求的相关性热力图')  \n",
    "plt.tight_layout()  \n",
    "plt.savefig('相关性热力图.png', dpi=300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e997857-07e5-4f00-a301-3d7897b57226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. SARIMAX模型 (包含外部变量)  \n",
    "print(\"\\n13. 使用SARIMAX模型考虑外部变量\")  \n",
    "# 选择相关性强的外部变量  \n",
    "selected_features = ['T2M_toc', 'QV2M_toc', 'T2M_san', 'W2M_dav']  # 示例，请根据相关性分析结果调整  \n",
    "\n",
    "# 创建外生变量矩阵  \n",
    "exog_train = train_data[selected_features]  \n",
    "exog_test = test_data[selected_features]  \n",
    "\n",
    "# 拟合SARIMAX模型  \n",
    "# (p,d,q) 为ARIMA参数，(P,D,Q,s) 为季节性参数  \n",
    "# 这里使用 (2,1,2)×(1,1,1,24) 作为示例  \n",
    "sarimax_model = sm.tsa.SARIMAX(  \n",
    "    train_data['nat_demand'],  \n",
    "    exog=exog_train,  \n",
    "    order=(p, d, q),  \n",
    "    seasonal_order=(1, 1, 1, 24),  # 季节性参数 (P,D,Q,s)，s=24表示24小时周期  \n",
    "    enforce_stationarity=False,  \n",
    "    enforce_invertibility=False  \n",
    ")  \n",
    "\n",
    "sarimax_results = sarimax_model.fit()  \n",
    "print(sarimax_results.summary())  \n",
    "\n",
    "# 使用SARIMAX模型进行预测  \n",
    "sarimax_predictions = sarimax_results.forecast(steps=len(test_data), exog=exog_test)  \n",
    "\n",
    "# 对比ARIMA和SARIMAX模型的预测结果  \n",
    "plt.figure(figsize=(15, 6))  \n",
    "plt.plot(test_data.index, test_data['nat_demand'], label='实际值')  \n",
    "plt.plot(test_data.index, predictions, color='red', label='ARIMA预测')  \n",
    "plt.plot(test_data.index, sarimax_predictions, color='green', label='SARIMAX预测')  \n",
    "plt.title('ARIMA vs SARIMAX 预测结果比较')  \n",
    "plt.xlabel('日期')  \n",
    "plt.ylabel('电力需求')  \n",
    "plt.legend()  \n",
    "plt.grid(True)  \n",
    "plt.tight_layout()  \n",
    "plt.savefig('ARIMA与SARIMAX比较.png', dpi=300)  \n",
    "\n",
    "# 计算SARIMAX模型的评估指标  \n",
    "sarimax_mse = mean_squared_error(test_data['nat_demand'], sarimax_predictions)  \n",
    "sarimax_rmse = np.sqrt(sarimax_mse)  \n",
    "sarimax_mae = mean_absolute_error(test_data['nat_demand'], sarimax_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c91e3-4a35-4228-a2aa-eab366b23eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. 总结: 显示最优模型及其参数  \n",
    "if sarimax_rmse < rmse:  \n",
    "    print(\"\\n最优模型: SARIMAX\")  \n",
    "    print(f\"最优参数: ARIMA({p},{d},{q})x季节性参数(1,1,1,24)\")  \n",
    "    print(f\"最优模型RMSE: {sarimax_rmse:.4f}\")  \n",
    "    print(f\"显著影响电力需求的外部变量: {selected_features}\")  \n",
    "else:  \n",
    "    print(\"\\n最优模型: ARIMA\")  \n",
    "    print(f\"最优参数: ARIMA({p},{d},{q})\")  \n",
    "    print(f\"最优模型RMSE: {rmse:.4f}\")  \n",
    "\n",
    "print(\"\\n分析完成!\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97abdcea-baa6-4513-86fc-dce83a835d49",
   "metadata": {},
   "source": [
    "# LSTM method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db489a2a-4b27-4dd9-bc8d-ffe1167c64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow --no-cache-dir -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce0a834-bb1a-47a8-a54e-16e0ad9e77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import qqplot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#1. 数据加载与预处理 \n",
    "file_path = 'continuous dataset_en.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：找不到文件 {file_path}。请确保文件路径正确。\")\n",
    "    # exit() # 在notebook环境中不exit\n",
    "\n",
    "df_ts = df.copy()\n",
    "df_ts[\"datetime\"] = pd.to_datetime(df_ts[\"datetime\"])\n",
    "df_ts = df_ts.set_index(\"datetime\") # 设置datetime为索引\n",
    "\n",
    "# --- 数据过滤：选择 2015-01-01 到 2019-12-31 的数据 ---\n",
    "print(f\"原始数据范围: {df_ts.index.min()} 到 {df_ts.index.max()}\")\n",
    "df_ts = df_ts['2015-01-01':'2019-12-31']\n",
    "print(f\"筛选后数据范围: {df_ts.index.min()} 到 {df_ts.index.max()}\")\n",
    "\n",
    "# 填充缺失值\n",
    "df_ts[\"nat_demand\"] = df_ts[\"nat_demand\"].ffill()\n",
    "numerical_cols = df_ts.select_dtypes(include=np.number).columns.difference(['nat_demand'])\n",
    "df_ts[numerical_cols] = df_ts[numerical_cols].fillna(df_ts[numerical_cols].median())\n",
    "\n",
    "# --- 2. 特征工程 ---\n",
    "# 时间特征\n",
    "df_ts['hour'] = df_ts.index.hour\n",
    "df_ts['dayofweek'] = df_ts.index.dayofweek\n",
    "df_ts['quarter'] = df_ts.index.quarter\n",
    "df_ts['month'] = df_ts.index.month\n",
    "df_ts['year'] = df_ts.index.year\n",
    "df_ts['dayofyear'] = df_ts.index.dayofyear\n",
    "df_ts['weekofyear'] = df_ts.index.isocalendar().week.astype(int)\n",
    "# Sin/Cos 变换\n",
    "df_ts['hour_sin'] = np.sin(2 * np.pi * df_ts['hour'] / 24)\n",
    "df_ts['hour_cos'] = np.cos(2 * np.pi * df_ts['hour'] / 24)\n",
    "df_ts['dayofweek_sin'] = np.sin(2 * np.pi * df_ts['dayofweek'] / 7)\n",
    "df_ts['dayofweek_cos'] = np.cos(2 * np.pi * df_ts['dayofweek'] / 7)\n",
    "df_ts['month_sin'] = np.sin(2 * np.pi * df_ts['month'] / 12)\n",
    "df_ts['month_cos'] = np.cos(2 * np.pi * df_ts['month'] / 12)\n",
    "df_ts['dayofyear_sin'] = np.sin(2 * np.pi * df_ts['dayofyear'] / 365)\n",
    "df_ts['dayofyear_cos'] = np.cos(2 * np.pi * df_ts['dayofyear'] / 365)\n",
    "df_ts['weekofyear_sin'] = np.sin(2 * np.pi * df_ts['weekofyear'] / 52)\n",
    "df_ts['weekofyear_cos'] = np.cos(2 * np.pi * df_ts['weekofyear'] / 52)\n",
    "# 滞后特征\n",
    "for lag in [1, 2, 3, 24, 48, 24*7]:\n",
    "    df_ts[f'nat_demand_lag_{lag}'] = df_ts['nat_demand'].shift(lag)\n",
    "# 滚动窗口特征\n",
    "for window in [24, 24*7]:\n",
    "    df_ts[f'nat_demand_rolling_mean_{window}'] = df_ts['nat_demand'].rolling(window=window).mean()\n",
    "# 节假日特征\n",
    "df_ts['holiday'] = df_ts['holiday'].fillna('None')\n",
    "holiday_dummies = pd.get_dummies(df_ts['holiday'], prefix='holiday', dummy_na=False)\n",
    "df_ts = pd.concat([df_ts, holiday_dummies], axis=1)\n",
    "df_ts.drop('holiday', axis=1, inplace=True)\n",
    "# Holiday_ID 和 school 特征保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12e77d-92af-432e-a88d-9a022630e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 数据准备用于 LSTM (按时间划分) ---\n",
    "\n",
    "# 删除由于滞后和滚动计算产生的NaN行\n",
    "df_lstm = df_ts.dropna().copy()\n",
    "print(f\"去除NaN后数据范围: {df_lstm.index.min()} 到 {df_lstm.index.max()}\")\n",
    "\n",
    "\n",
    "# --- 定义训练集和测试集 (基于时间) ---\n",
    "test_days = 30\n",
    "split_date = df_lstm.index.max() - pd.Timedelta(days=test_days - 1) # 测试集开始日期 (包含)\n",
    "split_date = split_date.normalize() #确保从一天的开始计算\n",
    "\n",
    "train_df = df_lstm.loc[df_lstm.index < split_date]\n",
    "test_df = df_lstm.loc[df_lstm.index >= split_date]\n",
    "\n",
    "print(f\"训练集范围: {train_df.index.min()} 到 {train_df.index.max()}\")\n",
    "print(f\"测试集范围: {test_df.index.min()} 到 {test_df.index.max()}\")\n",
    "print(f\"训练集大小: {len(train_df)}, 测试集大小: {len(test_df)}\")\n",
    "\n",
    "\n",
    "# 定义特征和目标\n",
    "feature_cols = [col for col in df_lstm.columns if col not in ['nat_demand']]\n",
    "target_col = 'nat_demand'\n",
    "\n",
    "# 数据标准化 (在训练集上拟合，然后转换训练集和测试集)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# 拟合训练集并转换\n",
    "X_train_scaled = scaler_X.fit_transform(train_df[feature_cols])\n",
    "y_train_scaled = scaler_y.fit_transform(train_df[target_col].values.reshape(-1, 1))\n",
    "\n",
    "# 转换测试集\n",
    "X_test_scaled = scaler_X.transform(test_df[feature_cols])\n",
    "y_test_scaled = scaler_y.transform(test_df[target_col].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# 创建时间序列数据所需的序列 (sequences)\n",
    "def create_sequences(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    # 确保循环不会超出 y 的边界\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        # 对应的 y 是时间步结束后的下一个值\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# 设定时间步长\n",
    "TIME_STEPS = 24 # 例如，使用过去 24 个小时的数据来预测下一个小时\n",
    "\n",
    "# 为训练集和测试集创建序列\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, TIME_STEPS)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, TIME_STEPS) # y_test_seq 是缩放后的目标，用于潜在对比，但主要用原始值评估\n",
    "\n",
    "print(f\"Prepared data for LSTM: X_train_seq shape {X_train_seq.shape}, y_train_seq shape {y_train_seq.shape}\")\n",
    "print(f\"Prepared data for LSTM: X_test_seq shape {X_test_seq.shape}, y_test_seq shape {y_test_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05bfd1-6163-4e8c-832a-419d2a1901c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 构建和训练 LSTM 模型 ---\n",
    "print(\"Building and training LSTM model...\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50,\n",
    "               return_sequences=True,\n",
    "               input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_seq, y_train_seq,\n",
    "                    epochs=70, #可以修改测试次数\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2, # 从训练序列中分验证集\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "print(\"LSTM model training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7175d-a84b-4078-9c56-1ecdd8c03c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 模型预测 (测试集) ---\n",
    "# 在测试序列上进行预测\n",
    "y_pred_scaled = model.predict(X_test_seq)\n",
    "\n",
    "# 将预测结果反标准化回原始尺度\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "\n",
    "# 确保我们有足够的实际值来匹配预测值\n",
    "if len(test_df) >= TIME_STEPS + len(y_pred):\n",
    "    test_indices_actual = test_df.index[TIME_STEPS : TIME_STEPS + len(y_pred)]\n",
    "    y_test_actual = test_df.loc[test_indices_actual, target_col].values\n",
    "else:\n",
    "     # 如果 test_df 不够长，可能需要调整逻辑或检查序列创建\n",
    "     print(\"警告：测试集的实际值数量不足以完全匹配预测值。\")\n",
    "     # 取尽可能多的值进行比较\n",
    "     available_length = len(test_df) - TIME_STEPS\n",
    "     test_indices_actual = test_df.index[TIME_STEPS : TIME_STEPS + available_length]\n",
    "     y_test_actual = test_df.loc[test_indices_actual, target_col].values\n",
    "     y_pred = y_pred[:available_length] # 截断预测值以匹配\n",
    "\n",
    "# 展平预测结果以便比较\n",
    "y_pred = y_pred.flatten()\n",
    "\n",
    "print(f\"实际值数量: {len(y_test_actual)}, 预测值数量: {len(y_pred)}\")\n",
    "# 再次确保长度一致 (通常在上面处理后应该一致)\n",
    "min_len = min(len(y_test_actual), len(y_pred))\n",
    "y_test_actual = y_test_actual[:min_len]\n",
    "y_pred = y_pred[:min_len]\n",
    "test_indices_actual = test_indices_actual[:min_len] # 同时调整索引长度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24788a4-ced4-4260-8350-167b577f155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 模型评估 (测试集) ---\n",
    "if len(y_test_actual) > 0 and len(y_pred) > 0: # 确保有数据进行评估\n",
    "    rmse = mean_squared_error(y_test_actual, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test_actual, y_pred)\n",
    "    r2 = r2_score(y_test_actual, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test_actual, y_pred)\n",
    "\n",
    "    print(f\"\\nLSTM 模型在测试集 ({test_days}天) 上的性能指标：\")\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"R²: {r2:.3f}\")\n",
    "else:\n",
    "    print(\"\\n无法进行模型评估，因为实际值或预测值为空。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb5047-9e48-4946-9773-0ee713f15366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. 可视化最终预测结果 (测试集) ---\n",
    "if len(y_test_actual) > 0 and len(y_pred) > 0:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(test_indices_actual, y_test_actual, label='Actual')\n",
    "    plt.plot(test_indices_actual, y_pred, label='LSTM Predict', color='red', alpha=0.8)\n",
    "    plt.title(f'LSTM Results (Test - Last{test_days}days)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Demand')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n无法可视化预测结果，因为实际值或预测值为空。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9c1c4-2c5f-4390-85e1-6e4e3ec3a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
